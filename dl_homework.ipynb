{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dl_homework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqWw3aP7wgOL"
      },
      "source": [
        "## Task 0.\n",
        "\n",
        "We have data corpus of text in 4 categories. Our task is to classify them into those categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T16:33:05.462367Z",
          "start_time": "2021-01-28T16:33:05.025062Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "o031RfNCWTvg",
        "outputId": "abfc260c-9224-4913-8e35-f104018d5956"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv('/content/train.csv', error_bad_lines=False)\n",
        "df_train = df_train.dropna()\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Российская сборная лидирует по итогам командно...</td>\n",
              "      <td>mchsgov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#СоветМЧС #МЧС #МЧСРОССИИ</td>\n",
              "      <td>mchsgov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Инспекторы ГИБДД Москвы приняли участие во Все...</td>\n",
              "      <td>mospolice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>В Главную Военно-Морскую Базу БФ в г.Балтийск ...</td>\n",
              "      <td>mil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Обвиняемые в хищении денежных средств у 32 пож...</td>\n",
              "      <td>mospolice</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     source\n",
              "0  Российская сборная лидирует по итогам командно...    mchsgov\n",
              "1                          #СоветМЧС #МЧС #МЧСРОССИИ    mchsgov\n",
              "2  Инспекторы ГИБДД Москвы приняли участие во Все...  mospolice\n",
              "3  В Главную Военно-Морскую Базу БФ в г.Балтийск ...        mil\n",
              "4  Обвиняемые в хищении денежных средств у 32 пож...  mospolice"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOJfFNs55GHT",
        "outputId": "99df111b-4836-4dcd-ebf9-36f9a3f52765"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9794, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx2PZCCkQu91"
      },
      "source": [
        "## 1. Data preprocessing\n",
        "\n",
        "\n",
        "* Bring all texts to the same length, replace words / tokens with numbers, factorize the target variable\n",
        "\n",
        "* Split everything into tokens using (https://github.com/huggingface/tokenizers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqgmxb6S45IB"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "SEQLEN = 250"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBcbFpdwAmCO",
        "outputId": "a3a7e8bb-a78f-4e14-8510-b88ed04127ca"
      },
      "source": [
        "!pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 7.2MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2021-01-27T01:31:30.333Z"
        },
        "id": "ITixp3GIRbTX"
      },
      "source": [
        "lines = [str(line) for line in df_train[\"text\"].to_numpy()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "zKUlUmVIQ1l6",
        "outputId": "02ce7e81-ebe4-4a2e-fb79-9ea915ad9d3a"
      },
      "source": [
        "MAX_LENGTH = max(map(len, lines))\r\n",
        "print(\"max length:\", MAX_LENGTH)\r\n",
        "\r\n",
        "plt.title('Number of words distribution')\r\n",
        "plt.hist(list(map(len, lines)), bins=25);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 13306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj19qmPdM8aI"
      },
      "source": [
        "from tokenizers.pre_tokenizers import Whitespace, Digits\r\n",
        "from tokenizers import pre_tokenizers \r\n",
        "from tokenizers import Tokenizer\r\n",
        "from tokenizers.models import BPE\r\n",
        "from tokenizers.trainers import BpeTrainer\r\n",
        "import tokenizers\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\r\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Sequence([Whitespace(), Digits(individual_digits=False)])\r\n",
        "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\r\n",
        "tokenizer.enable_padding(pad_id=0, pad_token=\"[PAD]\", length=SEQLEN)\r\n",
        "\r\n",
        "tokenizer.train_from_iterator(lines, trainer=trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RioWTbxiuTrb"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "words_to_remove = stopwords.words(\"russian\")\r\n",
        "tokenizer.add_special_tokens(tokens = words_to_remove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ_mmzjGFx8t"
      },
      "source": [
        "#ids_to_remove = [tokenizer.encode(word).ids[0] for word in words_to_remove]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqoFIfldjvNA"
      },
      "source": [
        "Let's use OHE for our target (it will be done a bit later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Io82xhYCw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b9372e-8a63-4a11-c535-6f41f3f6e884"
      },
      "source": [
        "target = list(set(df_train['source'].values))\r\n",
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mospolice', 'mil', 'mchsgov', 'russianpost']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PitPH523-fDI"
      },
      "source": [
        "Now to the data itself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWovobZHixod"
      },
      "source": [
        "train_text_x = []\r\n",
        "\r\n",
        "for line in df_train['text']:\r\n",
        "  train_text_x.append(list(tokenizer.encode(line).ids)[:SEQLEN])\r\n",
        "df_train['tokens'] = train_text_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUYaNHk3_Mxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c908264-96fe-4166-f5b5-aeab4d287242"
      },
      "source": [
        "MAX_LENGTH = max(map(len, df_train['tokens']))\r\n",
        "print(\"max length:\", MAX_LENGTH)\r\n",
        "MIN_LENGTH = min(map(len, df_train['tokens']))\r\n",
        "print(\"min length:\", MIN_LENGTH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 250\n",
            "min length: 250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcMpCKeS-heq"
      },
      "source": [
        "Same with our test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "J5JnFl1wZeyp",
        "outputId": "0fe49d3a-ddbd-4197-bc04-4f0e5fd0d5e0"
      },
      "source": [
        "df_test = pd.read_csv('/content/test.csv')\r\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>На полигоне «Погоново» Воронежской области про...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#БудниМЧС #МЧС #МЧСРОССИИ &lt;br&gt;&lt;br&gt;Пожарные тра...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Друзья, напоминаем вам, что завтра единый день...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Настольная игра: \"Королевская почта\"&lt;br&gt;&lt;br&gt;По...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Миллиарды писем разносят по почтовым ящикам на...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  На полигоне «Погоново» Воронежской области про...\n",
              "1  #БудниМЧС #МЧС #МЧСРОССИИ <br><br>Пожарные тра...\n",
              "2  Друзья, напоминаем вам, что завтра единый день...\n",
              "3  Настольная игра: \"Королевская почта\"<br><br>По...\n",
              "4  Миллиарды писем разносят по почтовым ящикам на..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppLT_DhOkGq-"
      },
      "source": [
        "test_text_x = []\r\n",
        "\r\n",
        "for line in df_test['text']:\r\n",
        "  if line != line:\r\n",
        "    line = ''\r\n",
        "  test_text_x.append(list(tokenizer.encode(line).ids)[:SEQLEN])\r\n",
        "df_test['tokens'] = test_text_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-XmxjpiwgOV"
      },
      "source": [
        "## 2. LSTM-net\n",
        "\n",
        "Build LSTM from scratch use this [architechture](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooXQyKxb90RK"
      },
      "source": [
        "from tensorflow.keras import Sequential\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0a81YTocWlX"
      },
      "source": [
        "in_tok, out_tok = 30000, len(target)\r\n",
        "out_dim=64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogopDyQDshrk"
      },
      "source": [
        "from keras import backend\r\n",
        "from keras.engine.topology import Layer\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "class my_lstm(Layer):\r\n",
        "    def __init__(self, units=32, **kwargs):\r\n",
        "      self.units = units\r\n",
        "      self.state_size = [units, units]\r\n",
        "      self.built = False\r\n",
        "      super(my_lstm, self).__init__(**kwargs)\r\n",
        "      \r\n",
        "    def build(self, in_sh):\r\n",
        "      self.b = [self.add_weight(name='bf', shape=(1, self.units), initializer='zeros'),\r\n",
        "                self.add_weight(name='bi', shape=(1, self.units), initializer='zeros'),\r\n",
        "                self.add_weight(name='bc', shape=(1, self.units), initializer='zeros'),\r\n",
        "                self.add_weight(name='b0', shape=(1, self.units), initializer='zeros')]\r\n",
        "      \r\n",
        "      self.xt = [self.add_weight(name='xft', shape=(in_sh[-1], self.units), initializer='uniform'),\r\n",
        "                self.add_weight(name='xit', shape=(in_sh[-1], self.units), initializer='uniform'),\r\n",
        "                self.add_weight(name='xct', shape=(in_sh[-1], self.units), initializer='uniform'),\r\n",
        "                self.add_weight(name='x0t', shape=(in_sh[-1], self.units), initializer='uniform')]\r\n",
        "\r\n",
        "      self.ht = [self.add_weight(name='hft', shape=(self.units, self.units), initializer='uniform'),\r\n",
        "                self.add_weight(name='hit', shape=(self.units, self.units), initializer='uniform'),\r\n",
        "                self.add_weight(name='hct', shape=(self.units, self.units), initializer='uniform'),\r\n",
        "                self.add_weight(name='h0t', shape=(self.units, self.units), initializer='uniform')]\r\n",
        "      self.built = True\r\n",
        "\r\n",
        "    def call(self, x, hc, mask):\r\n",
        "      h, c = hc\r\n",
        "\r\n",
        "      c_new = (backend.sigmoid(backend.dot(h, self.ht[0]) + self.b[0] + backend.dot(x, self.xt[0])) * c +\r\n",
        "        backend.sigmoid(backend.dot(h, self.ht[1]) + self.b[1] + backend.dot(x, self.xt[1])) *\r\n",
        "        backend.tanh(backend.dot(h, self.ht[2]) + self.b[2] + backend.dot(x, self.xt[2])))\r\n",
        "      \r\n",
        "      h_new = (backend.sigmoid(backend.dot(h, self.ht[3]) + self.b[3] + backend.dot(x, self.xt[3])) *\r\n",
        "              backend.tanh(c_new))\r\n",
        "      if mask != None:\r\n",
        "        h_new = tf.where(mask, h_new, h)\r\n",
        "        c_new = tf.where(mask, c_new, c)\r\n",
        "      \r\n",
        "      return h_new, c_new\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCWHtQET9O5r"
      },
      "source": [
        "from keras.layers import Embedding\r\n",
        "#from tensorflow.python.keras.engine.base_layer import Layer\r\n",
        "from keras.utils.generic_utils import to_list\r\n",
        "from keras.utils.generic_utils import unpack_singleton\r\n",
        "\r\n",
        "class rnn(Layer):\r\n",
        "  def __init__(self,\r\n",
        "               cell,\r\n",
        "               **kwargs):\r\n",
        "    self.cell = cell\r\n",
        "    #self.embedding = layers.Embedding(in_tok, out_dim, mask_zero=True)\r\n",
        "    super(rnn, self).__init__(**kwargs)\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    if not self.cell.built:\r\n",
        "      self.cell.build(input_shape)\r\n",
        "      self.cell.built = True\r\n",
        "    self.built = True\r\n",
        "  \r\n",
        "  def call(self, inputs, mask=None, **kwargs):\r\n",
        "    hc = [tf.zeros(shape=(tf.shape(inputs)[0], self.cell.units)),\r\n",
        "          tf.zeros(shape=(tf.shape(inputs)[0], self.cell.units))]\r\n",
        "    \r\n",
        "    for i in range(SEQLEN):\r\n",
        "      hc[0], hc[1] = self.cell.call(inputs[:,i,:], hc, tf.reshape(mask[:, i], [tf.shape(inputs)[0], 1]))\r\n",
        "    return hc[0]\r\n",
        "\r\n",
        "  def get_config(self):\r\n",
        "    config = super().get_config().copy()\r\n",
        "    config.update({\r\n",
        "        'return_sequences': self.return_sequences \r\n",
        "    })\r\n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjeg3rwEHCJp"
      },
      "source": [
        "## 3. Model\n",
        "\n",
        "Use your cell with some others for the final model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgbg7HHJwxLN"
      },
      "source": [
        "from keras.layers import RNN, Dense, Activation,LSTM, Embedding, TimeDistributed\r\n",
        "from keras.models import Model\r\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh2FFZ5ROvAK"
      },
      "source": [
        "batch_size = 128\r\n",
        "epochs = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwSxzGt_wZM3"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(in_tok, out_dim, input_length=SEQLEN, mask_zero=True))\r\n",
        "model.add(rnn(my_lstm(units = SEQLEN)))\r\n",
        "model.add((Dense(out_tok)))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lf7VHPBg6b1",
        "outputId": "a5fa4126-0ae9-4603-c4bb-bd698bfd9b07"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 250, 64)           1920000   \n",
            "_________________________________________________________________\n",
            "rnn (rnn)                    (None, 250)               315000    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 1004      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 2,236,004\n",
            "Trainable params: 2,236,004\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bs3aoA4yh4Y",
        "outputId": "a6cbd7c3-5e54-4bbd-9c5d-6cce37f88071"
      },
      "source": [
        "[print(i.shape, i.dtype) for i in model.inputs]\r\n",
        "print('-------')\r\n",
        "[print(o.shape, o.dtype) for o in model.outputs]\r\n",
        "print('-------')\r\n",
        "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 250) <dtype: 'float32'>\n",
            "-------\n",
            "(None, 4) <dtype: 'float32'>\n",
            "-------\n",
            "embedding (None, 250) float32\n",
            "rnn (None, 250, 64) float32\n",
            "dense (None, 250) float32\n",
            "activation (None, 4) float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QWfIiNPoq8m"
      },
      "source": [
        "Prepare batch and encode our target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yidzXICQmCGb"
      },
      "source": [
        "id_to_source = {0: 'mchsgov', 1: 'mil', 2: 'mospolice', 3: 'russianpost'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bXGN-fNraKz",
        "outputId": "651fd125-a90e-41f8-ac96-5125644e546d"
      },
      "source": [
        "df_train_target = pd.get_dummies(df_train['source'])\r\n",
        "print(df_train_target.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   mchsgov  mil  mospolice  russianpost\n",
            "0        1    0          0            0\n",
            "1        1    0          0            0\n",
            "2        0    0          1            0\n",
            "3        0    1          0            0\n",
            "4        0    0          1            0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MnE19l6_eD9"
      },
      "source": [
        "untoked_data - used for a model with tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spg4r-dir30x"
      },
      "source": [
        "train_x, test_x, untoked_train, untoked_test, train_y, test_y = train_test_split(train_text_x, df_train_target, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POViVOK4pf1n"
      },
      "source": [
        "class batch_gen(object):\r\n",
        "    def __init__(self, feat, target, batch_size):\r\n",
        "      self.feat = feat\r\n",
        "      self.target = target\r\n",
        "      self.id = 0\r\n",
        "      self.batch_size = batch_size\r\n",
        "    def generate(self):\r\n",
        "      x = np.zeros((self.batch_size, SEQLEN))\r\n",
        "      y = np.zeros((self.batch_size, SEQLEN, self.target.shape[1]))\r\n",
        "      while 1:\r\n",
        "        if self.id + self.batch_size > len(self.feat):\r\n",
        "          self.id = 0\r\n",
        "        x = np.asarray(self.feat[self.id : self.id + batch_size])\r\n",
        "        x = np.asarray([np.asarray(line) for line in x])\r\n",
        "\r\n",
        "        y = np.asarray(np.asarray(self.target[self.id : self.id + batch_size]))\r\n",
        "        self.id += 7\r\n",
        "        yield x, y\r\n",
        "\r\n",
        "train_data_generator = batch_gen(train_x, train_y, batch_size)\r\n",
        "valid_data_generator = batch_gen(test_x, test_y, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49kKygN-oZ5F",
        "outputId": "a33e74c4-d1c2-43b4-b94b-9210bed7210f"
      },
      "source": [
        "model.fit_generator(train_data_generator.generate(), len(train_x)//(batch_size), epochs=17,\r\n",
        "                        validation_data=valid_data_generator.generate(),\r\n",
        "                        validation_steps=len(test_x)//(batch_size))#, callbacks=[checkpointer])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/17\n",
            "61/61 [==============================] - 128s 436ms/step - loss: 1.2789 - categorical_accuracy: 0.4541 - val_loss: 0.9496 - val_categorical_accuracy: 0.5813\n",
            "Epoch 2/17\n",
            "61/61 [==============================] - 13s 209ms/step - loss: 0.4829 - categorical_accuracy: 0.8634 - val_loss: 1.2725 - val_categorical_accuracy: 0.5927\n",
            "Epoch 3/17\n",
            "61/61 [==============================] - 13s 211ms/step - loss: 0.3050 - categorical_accuracy: 0.9086 - val_loss: 1.0345 - val_categorical_accuracy: 0.7021\n",
            "Epoch 4/17\n",
            "61/61 [==============================] - 13s 217ms/step - loss: 0.2432 - categorical_accuracy: 0.9250 - val_loss: 0.7270 - val_categorical_accuracy: 0.7635\n",
            "Epoch 5/17\n",
            "61/61 [==============================] - 13s 212ms/step - loss: 0.1648 - categorical_accuracy: 0.9504 - val_loss: 0.6172 - val_categorical_accuracy: 0.7844\n",
            "Epoch 6/17\n",
            "61/61 [==============================] - 13s 214ms/step - loss: 0.1515 - categorical_accuracy: 0.9564 - val_loss: 0.5178 - val_categorical_accuracy: 0.7948\n",
            "Epoch 7/17\n",
            "61/61 [==============================] - 13s 213ms/step - loss: 0.2234 - categorical_accuracy: 0.9319 - val_loss: 0.7516 - val_categorical_accuracy: 0.6932\n",
            "Epoch 8/17\n",
            "61/61 [==============================] - 13s 213ms/step - loss: 0.2756 - categorical_accuracy: 0.9258 - val_loss: 0.5804 - val_categorical_accuracy: 0.7703\n",
            "Epoch 9/17\n",
            "61/61 [==============================] - 13s 215ms/step - loss: 0.2947 - categorical_accuracy: 0.9063 - val_loss: 0.3587 - val_categorical_accuracy: 0.8500\n",
            "Epoch 10/17\n",
            "61/61 [==============================] - 13s 212ms/step - loss: 0.2145 - categorical_accuracy: 0.9325 - val_loss: 0.3190 - val_categorical_accuracy: 0.8932\n",
            "Epoch 11/17\n",
            "61/61 [==============================] - 13s 212ms/step - loss: 0.1524 - categorical_accuracy: 0.9563 - val_loss: 0.4220 - val_categorical_accuracy: 0.8719\n",
            "Epoch 12/17\n",
            "61/61 [==============================] - 13s 211ms/step - loss: 0.1249 - categorical_accuracy: 0.9677 - val_loss: 0.2724 - val_categorical_accuracy: 0.9078\n",
            "Epoch 13/17\n",
            "61/61 [==============================] - 13s 212ms/step - loss: 0.0746 - categorical_accuracy: 0.9837 - val_loss: 0.2557 - val_categorical_accuracy: 0.9172\n",
            "Epoch 14/17\n",
            "61/61 [==============================] - 13s 213ms/step - loss: 0.1648 - categorical_accuracy: 0.9531 - val_loss: 0.3130 - val_categorical_accuracy: 0.9302\n",
            "Epoch 15/17\n",
            "61/61 [==============================] - 13s 213ms/step - loss: 0.1567 - categorical_accuracy: 0.9635 - val_loss: 0.2249 - val_categorical_accuracy: 0.9292\n",
            "Epoch 16/17\n",
            "61/61 [==============================] - 13s 214ms/step - loss: 0.0971 - categorical_accuracy: 0.9742 - val_loss: 0.4196 - val_categorical_accuracy: 0.8630\n",
            "Epoch 17/17\n",
            "61/61 [==============================] - 13s 212ms/step - loss: 0.1258 - categorical_accuracy: 0.9661 - val_loss: 0.4482 - val_categorical_accuracy: 0.8583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f06d02bef90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24VNfcMWHaKJ"
      },
      "source": [
        "## Improve our classifier model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLedkG56zsB2"
      },
      "source": [
        "Let's try usding model with 2 separate inputs one of which will be TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRWTlHWFOJx4"
      },
      "source": [
        "from keras.layers import Conv1D, GlobalMaxPooling1D\r\n",
        "out_dim = 128\r\n",
        "in_tok = 30000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPFKgTtQEe6I"
      },
      "source": [
        "train_x, test_x, untoked_train, untoked_test, train_y, test_y = train_test_split(train_text_x, lines, df_train_target, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO59gX8JAEbe"
      },
      "source": [
        "from keras.layers import Activation, concatenate, Input\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "num_feats = 50\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(max_features=num_feats, analyzer='char')\r\n",
        "feats = vectorizer.fit_transform(untoked_train).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTmIP7pJDKtm",
        "outputId": "86b4915e-56ca-4e87-df8d-e9681541e4c5"
      },
      "source": [
        "input_tfidf = Input(shape=(num_feats,))\r\n",
        "input_text = Input(shape=(SEQLEN,))\r\n",
        "\r\n",
        "embedding = Embedding(in_tok, 60, input_length=SEQLEN)(input_text)\r\n",
        "\r\n",
        "conv1 = (Conv1D(128, 5, activation='relu'))(embedding)\r\n",
        "pool = (GlobalMaxPooling1D())(conv1)\r\n",
        "flatten = tf.keras.layers.Flatten()(pool)\r\n",
        "\r\n",
        "concatenated = concatenate([input_tfidf, flatten])\r\n",
        "\r\n",
        "dense1 = Dense(32, activation='relu')(concatenated)\r\n",
        "dense2 = Dense(32, activation='relu')(dense1)\r\n",
        "dense3 = Dense(out_tok, activation='sigmoid')(dense2)\r\n",
        "\r\n",
        "model_with_tidf = Model(inputs=[input_tfidf, input_text], outputs=dense3)\r\n",
        "\r\n",
        "model_with_tidf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "model_with_tidf.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 250)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 250, 60)      1800000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 246, 128)     38528       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 128)          0           global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 178)          0           input_1[0][0]                    \n",
            "                                                                 flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          22912       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           4128        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            132         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,865,700\n",
            "Trainable params: 1,865,700\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIZtJkWlEiYs"
      },
      "source": [
        "dummy_train_x = np.asarray([np.asarray(line) for line in train_x])\r\n",
        "dummy_test_x = np.asarray([np.asarray(line) for line in test_x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3bR_nRqKeGl"
      },
      "source": [
        "valid_feats = vectorizer.transform(untoked_test).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djN4Du2OD-g7"
      },
      "source": [
        "model_with_tidf.fit(x=[np.asarray(feats), np.asarray(dummy_train_x)], y=train_y,\r\n",
        "                    epochs=10,\r\n",
        "                    verbose=False,\r\n",
        "                    validation_data=([np.asarray(valid_feats), np.asarray(dummy_test_x)], test_y),\r\n",
        "                    batch_size=40)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}